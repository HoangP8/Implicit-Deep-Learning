import random
import torch
import numpy as np

def set_seed(seed):
    """
    Set seed for reproducibility.
    """
    random.seed(seed) 
    np.random.seed(seed) 
    torch.manual_seed(seed) 
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)


def print_model_size(model):
    """
    Print the total number of trainable parameters in a model.
    """
    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Total number of parameters: {total_params}")
    

def get_batch(data, block_size, batch_size, device):
    """
    Create a batch of data for training or evaluation.
    
    Args:
    - data: Tensor containing sequence data.
    - block_size: Number of data points in each sequence.
    - batch_size: Number of sequences per batch.
    - device: Device to load the batch.
    
    Returns:
    - Input and target batch tensors.
    """
    ix = torch.randint(len(data) - block_size, (batch_size,))
    x = torch.stack([data[i : i + block_size] for i in ix])
    y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])
    return x.to(device), y.to(device)


@torch.no_grad()
def estimate_loss(model, data, block_size, batch_size, device, eval_iters):
    """
    Estimate the average loss of a model over specified iterations.
    
    Args:
    - model: Model to evaluate.
    - data: Data dictionary with 'train' and 'val' data.
    - block_size: Sequence length.
    - batch_size: Number of sequences in each batch.
    - device: Computation device.
    - eval_iters: Number of iterations to average over.
    
    Returns:
    - Average loss dictionary for training and validation data.
    """
    out = {}
    model.eval()
    for split in ["train", "val"]:
        losses = torch.zeros(eval_iters)
        for k in range(eval_iters):
            X, Y = get_batch(data[split], block_size, batch_size, device)
            logits, loss = model(X, Y)
            losses[k] = loss.item()
        out[split] = losses.mean()
    model.train()
    return out


def generate_text(args, idl_model, additional_data, device):
    """
    Generate text using a pre-trained language model.
    
    Args:
    - args: Configurations from main.py
    - idl_model: Trained implicit language model.
    - additional_data: Data needed for generation (e.g., tokenizer).
    - device: Device for running the model.
    
    Returns:
    - The text generated by the model.
    """
    if args.dataset == "tinyshakespeare":
        context = torch.zeros((1, 1), dtype=torch.long, device=device)
        generated_ids = idl_model.generate(context, args.max_new_tokens, args.block_size)[0].tolist()
        generated_text_idl = "".join([additional_data[i] for i in generated_ids])

    elif args.dataset == "tinystories":
        context = torch.tensor(additional_data.encode('\n'), dtype=torch.long, device=device).unsqueeze(0)
        generated_text_idl = additional_data.decode(
            idl_model.generate(context, args.max_new_tokens, args.block_size)[0].tolist()
        )

    elif args.dataset == "wikitext":
        context = torch.tensor(additional_data.encode_ordinary("\n"), dtype=torch.int, device=device).unsqueeze(0)
        generated_text_idl = additional_data.decode(
            idl_model.generate(context, args.max_new_tokens, args.block_size)[0].tolist()
        )

    else:
        raise NotImplementedError(f"Text generation for dataset {args.dataset} is not supported.")

    return generated_text_idl

